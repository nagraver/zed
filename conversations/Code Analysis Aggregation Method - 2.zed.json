{"id":"9ad0ee65-ef9a-48c1-b896-99a8941e73bf","zed":"context","version":"0.4.0","text":"\n\n\nУ меня есть такая функция:\ndef analyze_single_file(file_path: str) -> str:\n    try:\n        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n            code_content = f.read()\n\n        response = client.chat.completions.create(\n            model=\"llama-3.1-8b-lexi-uncensored-v2\",\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": (\n                        \"You're a senior code analyst. Analyze the provided code and describe:\\n\"\n                        \"1. Основное назначение файла\\n\"\n                        \"2. Ключевые функции/классы\\n\"\n                        \"3. Входные/выходные данные (если применимо)\\n\"\n                        \"4. Зависимости (если видны)\\n\"\n                        \"5. Особенности реализации\\n\"\n                        \"Будь лаконичным (3-5 предложений).\\n\"\n                        \"Отвечай на русском языке.\"\n                    ),\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Проанализируй этот код:\\n\\n{code_content}\",\n                },\n            ],\n            temperature=0.2,\n        )\n\n        if response.choices and len(response.choices) > 0:\n            return response.choices[0].message.content.strip()\n        return \"Не удалось проанализировать код\"\n\n    except Exception as e:\n        return f\"Ошибка при анализе файла {file_path}: {str(e)}\"\n\nОна выполняется множество раз для каждого файла в проекте, чтобы проанализировать его полностью. Как мне сделать так, чтобы она не отчитывалась о каждом файле, а только о проекте в целом?\n<think>\nLet's understand what the function does and how to modify it to analyze the entire project rather than individual files.\n\nThe `analyze_single_file` function:\n1. Opens a file and reads its content\n2. Sends the content to an LLM (llama-3.1-8b-lexi-uncensored-v2) via the client API\n3. Asks the LLM to analyze the code with specific criteria (purpose, key functions, I/O, dependencies, implementation details)\n4. Returns the LLM's analysis\n\nYou mentioned that this function is run for each file in the project individually, but you want to have a single analysis of the entire project instead of separate analyses for each file.\n\nHere's how we can approach this:\n\n1. We need to collect information from all files\n2. Summarize this information or send it all together to the LLM to get a holistic analysis\n3. Since there may be too many files to send everything at once (due to token limits), we might need a strategy to summarize or extract key information\n\nLet me propose a solution:\n\n```python\ndef analyze_project(project_path: str) -> str:\n    try:\n        # Step 1: Collect all relevant files\n        file_paths = []\n        for root, dirs, files in os.walk(project_path):\n            for file in files:\n                if file.endswith('.py'):  # or any other extensions you're interested in\n                    file_paths.append(os.path.join(root, file))\n        \n        # Step 2: Either analyze each file briefly and then summarize, or directly analyze the project structure\n        \n        # Option 1: Analyze each file briefly and collect results\n        file_analyses = {}\n        for file_path in file_paths:\n            relative_path = os.path.relpath(file_path, project_path)\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    content = f.read()\n                    # Maybe just extract key info like imports, class/function definitions\n                    # This could be a simplified analysis to save tokens\n                    file_analyses[relative_path] = extract_key_info(content)\n            except Exception as e:\n                file_analyses[relative_path] = f\"Error reading file: {str(e)}\"\n        \n        # Step 3: Send the collected information to the LLM for a holistic analysis\n        project_structure = {\n            \"file_count\": len(file_paths),\n            \"files\": file_analyses,\n            # Could include directory structure, etc.\n        }\n        \n        response = client.chat.completions.create(\n            model=\"llama-3.1-8b-lexi-uncensored-v2\",\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": (\n                        \"You're a senior code analyst. Analyze the provided project structure and describe:\\n\"\n                        \"1. Общее назначение проекта\\n\"\n                        \"2. Архитектура и основные компоненты\\n\"\n                        \"3. Ключевые зависимости\\n\"\n                        \"4. Основной поток данных\\n\"\n                        \"5. Особенности реализации\\n\"\n                        \"Предоставь полный анализ проекта (10-15 предложений).\\n\"\n                        \"Отвечай на русском языке.\"\n                    ),\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Проанализируй эту структуру проекта:\\n\\n{json.dumps(project_structure, indent=2, ensure_ascii=False)}\",\n                },\n            ],\n            temperature=0.2,\n        )\n\n        if response.choices and len(response.choices) > 0:\n            return response.choices[0].message.content.strip()\n        return \"Не удалось проанализировать проект\"\n\n    except Exception as e:\n        return f\"Ошибка при анализе проекта: {str(e)}\"\n\ndef extract_key_info(content: str) -> dict:\n    \"\"\"Extract key information from file content to reduce token count.\"\"\"\n    # This could use regex or AST parsing to extract:\n    # - Imports\n    # - Class definitions\n    # - Function signatures\n    # - Docstrings\n    # Implementation depends on your needs and language\n    # ...\n    return {\n        \"summary\": \"Brief content summary\",\n        \"imports\": [\"list\", \"of\", \"imports\"],\n        \"classes\": [\"list\", \"of\", \"classes\"],\n        \"functions\": [\"list\", \"of\", \"functions\"],\n    }\n```\n\nAlternative approach if the project is too large for token limits:\n\n```python\ndef analyze_project(project_path: str) -> str:\n    try:\n        # Step 1: Collect project structure information\n        file_structure = {}\n        for root, dirs, files in os.walk(project_path):\n            rel_dir = os.path.relpath(root, project_path)\n            if rel_dir == '.':\n                rel_dir = ''\n            \n            dir_files = []\n            for file in files:\n                if file.endswith(('.py', '.js', '.ts', '.java')):  # Add relevant extensions\n                    file_path = os.path.join(root, file)\n                    try:\n                        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                            content = f.read()\n                            dir_files.append({\n                                \"name\": file,\n                                \"size\": len(content),\n                                \"functions\": count_functions(content),\n                                \"classes\": count_classes(content),\n                            })\n                    except:\n                        dir_files.append({\"name\": file, \"error\": \"Could not read file\"})\n            \n            if dir_files:\n                if rel_dir:\n                    file_structure[rel_dir] = dir_files\n                else:\n                    file_structure[\"root\"] = dir_files\n        \n        # Step 2: Analyze important files (e.g., main.py, README.md)\n        key_files = find_key_files(project_path)\n        key_file_contents = {}\n        for file_path in key_files:\n            rel_path = os.path.relpath(file_path, project_path)\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    key_file_contents[rel_path] = f.read()\n            except:\n                key_file_contents[rel_path] = \"Error reading file\"\n        \n        # Step 3: Send summarized information to the LLM\n        project_info = {\n            \"structure\": file_structure,\n            \"key_files\": key_file_contents,\n        }\n        \n        response = client.chat.completions.create(\n            model=\"llama-3.1-8b-lexi-uncensored-v2\",\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": (\n                        \"You're a senior code analyst. Analyze the provided project information and describe:\\n\"\n                        \"1. Общее назначение проекта\\n\"\n                        \"2. Архитектура и основные компоненты\\n\"\n                        \"3. Ключевые зависимости\\n\"\n                        \"4. Основной поток данных\\n\"\n                        \"5. Особенности реализации\\n\"\n                        \"Предоставь полный анализ проекта (10-15 предложений).\\n\"\n                        \"Отвечай на русском языке.\"\n                    ),\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Проанализируй эту информацию о проекте:\\n\\n{json.dumps(project_info, indent=2, ensure_ascii=False)}\",\n                },\n            ],\n            temperature=0.2,\n        )\n\n        if response.choices and len(response.choices) > 0:\n            return response.choices[0].message.content.strip()\n        return \"Не удалось проанализировать проект\"\n\n    except Exception as e:\n        return f\"Ошибка при анализе проекта: {str(e)}\"\n\ndef find_key_files(project_path: str) -> list:\n    \"\"\"Find important files like README, main entry points, etc.\"\"\"\n    key_files = []\n    important_patterns = [\n        \"README.md\", \"setup.py\", \"requirements.txt\", \"package.json\",\n        \"main.py\", \"app.py\", \"index.js\", \"config.py\", \"settings.py\"\n    ]\n    \n    for root, _, files in os.walk(project_path):\n        for pattern in important_patterns:\n            for file in files:\n                if file == pattern or file.endswith(pattern):\n                    key_files.append(os.path.join(root, file))\n    \n    return key_files\n\ndef count_functions(content: str) -> int:\n    \"\"\"Count number of function definitions in the content.\"\"\"\n    # Simple implementation, could be improved with proper parsing\n    return content.count(\"def \")\n\ndef count_classes(content: str) -> int:\n    \"\"\"Count number of class definitions in the content.\"\"\"\n    # Simple implementation, could be improved with proper parsing\n    return content.count(\"class \")\n```\n\nThese approaches face a challenge: if the project is large, we might hit token limits when sending all the information to the LLM. We might need to:\n\n1. Focus on key files and high-level structure\n2. Use a hierarchical approach where we analyze parts of the project and then combine those analyses\n3. Use more sophisticated code summarization techniques\n\nLet me provide a more concise solution that should work for most reasonable-sized projects:\n</think>\n\n# Анализ всего проекта вместо отдельных файлов\n\nЧтобы анализировать проект в целом, а не отдельные файлы, нужно изменить подход. Вот решение:\n\n```python\ndef analyze_project(project_directory: str) -> str:\n    # Сбор информации о проекте\n    file_summaries = []\n    file_count = 0\n    \n    # Обход всех файлов проекта\n    for root, _, files in os.walk(project_directory):\n        for file in files:\n            # Фильтр по нужным расширениям\n            if file.endswith(('.py', '.js', '.html', '.css')):  # добавьте другие по необходимости\n                file_path = os.path.join(root, file)\n                rel_path = os.path.relpath(file_path, project_directory)\n                file_count += 1\n                \n                try:\n                    # Получаем краткую информацию о файле\n                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                        content = f.read()\n                        # Добавляем только базовую информацию о файле\n                        file_summaries.append(f\"{rel_path}: {len(content)} строк\")\n                except Exception:\n                    pass\n    \n    # Если файлов слишком много, ограничиваем список\n    if len(file_summaries) > 30:\n        file_summaries = file_summaries[:30] + [f\"... и еще {file_count - 30} файлов\"]\n    \n    # Анализ структуры проекта целиком\n    response = client.chat.completions.create(\n        model=\"llama-3.1-8b-lexi-uncensored-v2\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"Ты опытный аналитик кода. Проанализируй структуру проекта и опиши:\\n\"\n                    \"1. Общее назначение проекта\\n\"\n                    \"2. Архитектура и основные компоненты\\n\"\n                    \"3. Технологический стек\\n\"\n                    \"4. Основной поток данных\\n\"\n                    \"5. Сильные и слабые стороны архитектуры\\n\"\n                    \"Ответ должен быть информативным (7-10 предложений).\\n\"\n                    \"Отвечай на русском языке.\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Проанализируй структуру проекта:\\n\\nСодержит {file_count} файлов.\\nПримеры файлов:\\n\" + \n                           \"\\n\".join(file_summaries),\n            },\n        ],\n        temperature=0.2,\n    )\n    \n    if response.choices and len(response.choices) > 0:\n        return response.choices[0].message.content.strip()\n    return \"Не удалось проанализировать проект\"\n```\n\nДля более глубокого анализа можно:\n\n1. **Анализировать ключевые файлы** (README.md, setup.py, main.py) полностью\n2. **Собирать метаданные** о каждом файле (импорты, классы, функции)\n3. **Использовать двухэтапный подход**:\n   - Сначала анализировать части проекта\n   - Затем собирать эти анализы в общий отчет\n\nЭто решение лучше, чем анализ отдельных файлов, потому что:\n- Выявляет взаимосвязи между компонентами\n- Дает понимание архитектуры на высоком уровне\n- Избегает повторения в анализе общих частей проекта\n\nТак и каким образом мне - Сначала анализировать части проекта\n   - Затем собирать эти анализы в общий отчет\n<think>\nПонимаю, вы хотите практические шаги по двухэтапному подходу, где сначала анализируются части проекта, а затем эти анализы собираются в общий отчет. Давайте я опишу это более детально:\n\n## Двухэтапный подход к анализу проекта\n\n### Этап 1: Анализ частей проекта\n\nМожно разделить проект на логические части и анализировать их отдельно. Вот пример реализации:\n\n```python\ndef analyze_project_components(project_directory: str) -> dict:\n    \"\"\"Анализирует компоненты проекта по отдельности и собирает результаты.\"\"\"\n    \n    # Шаг 1: Группировка файлов по категориям/модулям\n    modules = {}\n    key_files = {}\n    \n    # Обнаружение ключевых файлов\n    important_patterns = [\"README.md\", \"setup.py\", \"requirements.txt\", \"package.json\", \n                          \"main.py\", \"app.py\", \"index.js\", \"config.py\"]\n    \n    for root, dirs, files in os.walk(project_directory):\n        # Определяем модуль на основе директории\n        rel_dir = os.path.relpath(root, project_directory)\n        module_name = rel_dir.replace(os.path.sep, \".\")\n        if module_name == \".\":\n            module_name = \"root\"\n            \n        # Инициализируем список файлов для модуля\n        if module_name not in modules:\n            modules[module_name] = []\n            \n        # Добавляем файлы в модуль\n        for file in files:\n            file_path = os.path.join(root, file)\n            \n            # Проверяем, является ли файл ключевым\n            if any(file == pattern or file.endswith(pattern) for pattern in important_patterns):\n                try:\n                    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                        key_files[os.path.join(rel_dir, file)] = f.read()\n                except:\n                    key_files[os.path.join(rel_dir, file)] = \"Ошибка чтения файла\"\n            \n            # Добавляем файл в модуль, если он имеет нужное расширение\n            if file.endswith(('.py', '.js', '.jsx', '.ts', '.tsx', '.html', '.css')):\n                modules[module_name].append(file_path)\n    \n    # Шаг 2: Анализируем каждый модуль по отдельности\n    module_analyses = {}\n    \n    for module_name, file_paths in modules.items():\n        if not file_paths:\n            continue\n            \n        # Берем только первые 5-10 файлов из модуля для анализа\n        sample_files = file_paths[:8]\n        file_contents = {}\n        \n        for file_path in sample_files:\n            rel_path = os.path.relpath(file_path, project_directory)\n            try:\n                with open(file_path, \"r\", encoding=\"utf-8\") as f:\n                    content = f.read()\n                    # Ограничиваем размер содержимого, чтобы не превысить лимиты токенов\n                    if len(content) > 2000:\n                        content = content[:2000] + \"...[обрезано]\"\n                    file_contents[rel_path] = content\n            except:\n                file_contents[rel_path] = \"Ошибка чтения файла\"\n        \n        # Если в модуле слишком много файлов, указываем это\n        if len(file_paths) > len(sample_files):\n            file_contents[\"note\"] = f\"Показаны {len(sample_files)} из {len(file_paths)} файлов\"\n        \n        # Анализируем модуль\n        if file_contents:\n            module_analyses[module_name] = analyze_module(module_name, file_contents)\n    \n    # Шаг 3: Добавляем анализ ключевых файлов\n    if key_files:\n        module_analyses[\"key_files\"] = analyze_key_files(key_files)\n    \n    return {\n        \"module_analyses\": module_analyses,\n        \"key_files_content\": key_files  # Передаем содержимое ключевых файлов для финального анализа\n    }\n\ndef analyze_module(module_name: str, file_contents: dict) -> str:\n    \"\"\"Анализирует отдельный модуль проекта.\"\"\"\n    try:\n        response = client.chat.completions.create(\n            model=\"llama-3.1-8b-lexi-uncensored-v2\",\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": (\n                        \"Ты опытный аналитик кода. Проанализируй код модуля и опиши:\\n\"\n                        \"1. Назначение модуля\\n\"\n                        \"2. Основную функциональность\\n\"\n                        \"3. Ключевые классы/функции\\n\"\n                        \"4. Как этот модуль взаимодействует с другими частями системы\\n\"\n                        \"Будь лаконичным (3-5 предложений).\\n\"\n                        \"Отвечай на русском языке.\"\n                    ),\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Проанализируй модуль '{module_name}':\\n\\n{json.dumps(file_contents, indent=2, ensure_ascii=False)}\",\n                },\n            ],\n            temperature=0.2,\n        )\n        \n        if response.choices and len(response.choices) > 0:\n            return response.choices[0].message.content.strip()\n        return \"Не удалось проанализировать модуль\"\n    except Exception as e:\n        return f\"Ошибка при анализе модуля: {str(e)}\"\n\ndef analyze_key_files(key_files: dict) -> str:\n    \"\"\"Анализирует ключевые файлы проекта.\"\"\"\n    try:\n        response = client.chat.completions.create(\n            model=\"llama-3.1-8b-lexi-uncensored-v2\",\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": (\n                        \"Ты опытный аналитик кода. Проанализируй ключевые файлы проекта и опиши:\\n\"\n                        \"1. Общее назначение проекта\\n\"\n                        \"2. Основные зависимости\\n\"\n                        \"3. Конфигурация проекта\\n\"\n                        \"4. Точки входа\\n\"\n                        \"Будь информативным, но лаконичным (4-6 предложений).\\n\"\n                        \"Отвечай на русском языке.\"\n                    ),\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Проанализируй ключевые файлы проекта:\\n\\n{json.dumps(key_files, indent=2, ensure_ascii=False)}\",\n                },\n            ],\n            temperature=0.2,\n        )\n        \n        if response.choices and len(response.choices) > 0:\n            return response.choices[0].message.content.strip()\n        return \"Не удалось проанализировать ключевые файлы\"\n    except Exception as e:\n        return f\"Ошибка при анализе ключевых файлов: {str(e)}\"\n```\n\n### Этап 2: Сборка анализов в общий отчет\n\nТеперь нужно собрать все полученные анализы в единый отчет:\n\n```python\ndef generate_project_report(project_directory: str) -> str:\n    \"\"\"Генерирует полный отчет о проекте на основе анализа компонентов.\"\"\"\n    \n    # Шаг 1: Получаем анализы отдельных частей\n    component_analyses = analyze_project_components(project_directory)\n    \n    # Шаг 2: Формируем краткое описание структуры проекта\n    directories = []\n    file_count = 0\n    file_types = set()\n    \n    for root, dirs, files in os.walk(project_directory):\n        rel_dir = os.path.relpath(root, project_directory)\n        if rel_dir != '.':\n            directories.append(rel_dir)\n        \n        for file in files:\n            file_count += 1\n            _, ext = os.path.splitext(file)\n            if ext:\n                file_types.add(ext)\n    \n    # Ограничиваем список директорий, если их много\n    if len(directories) > 15:\n        directories = directories[:15] + [f\"... и еще {len(directories) - 15} директорий\"]\n    \n    structure_info = {\n        \"directories\": directories,\n        \"file_count\": file_count,\n        \"file_types\": list(file_types),\n        \"module_count\": len(component_analyses[\"module_analyses\"])\n    }\n    \n    # Шаг 3: Создаем финальный отчет\n    report_data = {\n        \"project_structure\": structure_info,\n        \"component_analyses\": component_analyses[\"module_analyses\"],\n    }\n    \n    try:\n        response = client.chat.completions.create(\n            model=\"llama-3.1-8b-lexi-uncensored-v2\",\n            messages=[\n                {\n                    \"role\": \"system\",\n                    \"content\": (\n                        \"Ты опытный аналитик кода. На основе предоставленных анализов компонентов проекта создай \"\n                        \"целостный отчет о проекте. Отчет должен включать:\\n\"\n                        \"1. Общее назначение и описание проекта\\n\"\n                        \"2. Архитектуру и основные компоненты\\n\"\n                        \"3. Технологический стек\\n\"\n                        \"4. Основные потоки данных\\n\"\n                        \"5. Сильные и слабые стороны архитектуры\\n\"\n                        \"6. Рекомендации по улучшению (если возможно)\\n\\n\"\n                        \"Отчет должен быть структурированным и информативным (15-20 предложений).\\n\"\n                        \"Отвечай на русском языке.\"\n                    ),\n                },\n                {\n                    \"role\": \"user\",\n                    \"content\": f\"Создай отчет о проекте на основе этих данных:\\n\\n{json.dumps(report_data, indent=2, ensure_ascii=False)}\",\n                },\n            ],\n            temperature=0.3,\n        )\n        \n        if response.choices and len(response.choices) > 0:\n            return response.choices[0].message.content.strip()\n        return \"Не удалось создать отчет о проекте\"\n    except Exception as e:\n        return f\"Ошибка при создании отчета: {str(e)}\"\n```\n\n### Объединение в основную функцию\n\n```python\ndef analyze_full_project(project_directory: str) -> str:\n    \"\"\"Выполняет полный анализ проекта с использованием двухэтапного подхода.\"\"\"\n    return generate_project_report(project_directory)\n```\n\n### Конкретные преимущества двухэтапного подхода:\n\n1. **Масштабируемость**: Работает с крупными проектами без превышения лимитов контекста LLM\n2. **Точность**: Анализ по модулям дает более глубокое понимание каждой части проекта\n3. **Целостность**: Финальный анализ учитывает взаимосвязи между компонентами\n4. **Гибкость**: Можно настроить детализацию анализа для разных частей проекта\n5. **Прозрачность**: Виден анализ отдельных компонентов, а не только общая картина\n\nТакой подход позволяет:\n- Получить детальное понимание каждого компонента\n- Выявить архитектурные особенности проекта\n- Получить целостное представление на основе анализа отдельных частей\n- Избежать проблем с превышением лимитов токенов при анализе крупных проектов\n</think>\n\n# Двухэтапный подход к анализу проекта\n\nВот практическая реализация двухэтапного подхода для анализа проекта:\n\n```python\nimport os\nimport json\nfrom collections import defaultdict\n\ndef analyze_project_in_two_stages(project_directory: str) -> str:\n    \"\"\"Анализирует проект в два этапа: сначала компоненты, затем создает общий отчет\"\"\"\n    \n    # Этап 1: Анализ компонентов проекта\n    component_analyses = analyze_components(project_directory)\n    \n    # Этап 2: Составление общего отчета\n    return create_final_report(project_directory, component_analyses)\n\ndef analyze_components(project_directory: str) -> dict:\n    \"\"\"Анализирует отдельные компоненты проекта\"\"\"\n    \n    # Организуем файлы по директориям/модулям\n    modules = defaultdict(list)\n    key_files = {}\n    \n    # Определяем ключевые файлы, которые нужно проанализировать отдельно\n    important_files = [\"README.md\", \"setup.py\", \"requirements.txt\", \"main.py\", \"app.py\"]\n    \n    # Собираем файлы по модулям и находим ключевые файлы\n    for root, _, files in os.walk(project_directory):\n        module = os.path.relpath(root, project_directory)\n        if module == '.':\n            module = 'root'\n            \n        for file in files:\n            if file.endswith(('.py', '.js', '.html', '.css', '.jsx', '.ts')):\n                file_path = os.path.join(root, file)\n                modules[module].append(file_path)\n                \n            # Сохраняем содержимое ключевых файлов\n            if file in important_files:\n                file_path = os.path.join(root, file)\n                try:\n                    with open(file_path, 'r', encoding='utf-8') as f:\n                        key_files[os.path.join(module, file)] = f.read()\n                except Exception:\n                    pass\n    \n    # Анализируем каждый модуль\n    module_analyses = {}\n    \n    for module_name, file_paths in modules.items():\n        # Пропускаем пустые модули\n        if not file_paths:\n            continue\n            \n        # Для анализа возьмем только до 5 файлов из модуля\n        sample_files = file_paths[:5]\n        module_content = {}\n        \n        for file_path in sample_files:\n            rel_path = os.path.relpath(file_path, project_directory)\n            try:\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    content = f.read()\n                    # Ограничиваем размер для больших файлов\n                    if len(content) > 2000:\n                        content = content[:2000] + \"...[обрезано]\"\n                    module_content[rel_path] = content\n            except Exception:\n                continue\n        \n        # Анализируем модуль, если удалось получить содержимое файлов\n        if module_content:\n            analysis = client.chat.completions.create(\n                model=\"llama-3.1-8b-lexi-uncensored-v2\",\n                messages=[\n                    {\n                        \"role\": \"system\",\n                        \"content\": (\n                            \"Ты эксперт по анализу кода. Проанализируй код модуля и опиши:\\n\"\n                            \"1. Назначение модуля\\n\"\n                            \"2. Основную функциональность\\n\"\n                            \"3. Взаимодействие с другими частями системы\\n\"\n                            \"Будь лаконичным (3-4 предложения).\\n\"\n                            \"Отвечай на русском языке.\"\n                        ),\n                    },\n                    {\n                        \"role\": \"user\",\n                        \"content\": f\"Проанализируй модуль '{module_name}' с этими файлами:\\n\\n\" + \n                                 \"\\n\".join([f\"Файл: {path}\\n{content[:200]}...\" for path, content in module_content.items()]),\n                    },\n                ],\n                temperature=0.2,\n            )\n            \n            if analysis.choices and len(analysis.choices) > 0:\n                module_analyses[module_name] = analysis.choices[0].message.content.strip()\n    \n    # Возвращаем результаты анализа всех компонентов\n    return {\n        \"module_analyses\": module_analyses,\n        \"key_files\": key_files\n    }\n\ndef create_final_report(project_directory: str, component_analyses: dict) -> str:\n    \"\"\"Создает итоговый отчет на основе анализа компонентов\"\"\"\n    \n    # Информация о структуре проекта\n    file_count = sum(len(files) for _, _, files in os.walk(project_directory))\n    dir_count = sum(1 for _ in os.walk(project_directory)) - 1  # -1 для корневого каталога\n    \n    # Создаем итоговый отчет\n    response = client.chat.completions.create(\n        model=\"llama-3.1-8b-lexi-uncensored-v2\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"Ты аналитик-архитектор ПО. На основе предоставленных анализов компонентов \"\n                    \"создай целостный отчет о проекте. Включи:\\n\"\n                    \"1. Общее назначение проекта\\n\"\n                    \"2. Архитектуру и структуру компонентов\\n\"\n                    \"3. Технологический стек\\n\"\n                    \"4. Взаимодействие между компонентами\\n\"\n                    \"5. Сильные и слабые стороны архитектуры\\n\"\n                    \"Отчет должен быть структурированным и информативным.\\n\"\n                    \"Отвечай на русском языке.\"\n                ),\n            },\n            {\n                \"role\": \"user\",\n                \"content\": (\n                    f\"Создай отчет о проекте со следующей информацией:\\n\\n\"\n                    f\"Проект содержит {file_count} файлов в {dir_count} директориях.\\n\\n\"\n                    f\"Анализы модулей:\\n{json.dumps(component_analyses['module_analyses'], indent=2, ensure_ascii=False)}\\n\\n\"\n                    f\"Ключевые файлы:\\n\" + \n                    \"\\n\".join([f\"- {path}\" for path in component_analyses['key_files'].keys()])\n                ),\n            },\n        ],\n        temperature=0.3,\n    )\n    \n    if response.choices and len(response.choices) > 0:\n        return response.choices[0].message.content.strip()\n    return \"Не удалось создать отчет о проекте\"\n```\n\n## Как это работает:\n\n1. **Первый этап: Анализ компонентов**\n   - Группируем файлы по модулям (директориям)\n   - Идентифицируем ключевые файлы (README, setup.py и т.д.)\n   - Анализируем каждый модуль отдельно с помощью LLM\n   - Получаем краткое описание каждого модуля\n\n2. **Второй этап: Создание общего отчета**\n   - Берем все анализы компонентов\n   - Добавляем информацию о структуре проекта\n   - Отправляем всё в LLM для создания целостного отчета\n   - Получаем финальный анализ с архитектурой и взаимосвязями\n\n## Преимущества этого подхода:\n\n- Работает с большими проектами, не превышая лимиты токенов\n- Дает более глубокое понимание архитектуры, чем прямой анализ\n- Позволяет увидеть связи между компонентами\n- Выявляет общий паттерн проектирования\n\nВызывайте функцию так: `report = analyze_project_in_two_stages(\"/путь/к/проекту\")`\n","messages":[{"id":{"replica_id":0,"value":0},"start":0,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":851}}},{"id":{"replica_id":0,"value":12},"start":51,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":852}}},{"id":{"replica_id":0,"value":17},"start":1672,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":853}}},{"id":{"replica_id":0,"value":138},"start":2013,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":854}}},{"id":{"replica_id":0,"value":350},"start":15739,"metadata":{"role":"assistant","status":{"Error":"cloud language model completion failed with status 400 Bad Request: messages.1.content.0.type: Expected `thinking` or `redacted_thinking`, but found `text`. When `thinking` is enabled, a final `assistant` message must start with a thinking block. We recommend you include thinking blocks from previous turns. To avoid this requirement, disable `thinking`. Please consult our documentation at https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking"},"timestamp":{"replica_id":0,"value":855}}},{"id":{"replica_id":0,"value":351},"start":15740,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":856}}},{"id":{"replica_id":0,"value":428},"start":15933,"metadata":{"role":"assistant","status":"Done","timestamp":{"replica_id":0,"value":857}}},{"id":{"replica_id":0,"value":429},"start":38055,"metadata":{"role":"user","status":"Done","timestamp":{"replica_id":0,"value":858}}}],"summary":"Code Analysis Aggregation Method","slash_command_output_sections":[{"range":{"start":0,"end":1},"icon":"Library","label":"Default","metadata":null}],"thought_process_output_sections":[{"range":{"start":2013,"end":11655}},{"range":{"start":15933,"end":29153}}]}